# Scripts avanc√©s et cas d'usage

## Nettoyage des cha√Ænes de caract√®res

### Mettre une cha√Æne de caract√®res sous une forme canonique normalis√©e

Si vous souhaitez r√©aliser un important travail de normalisation des cha√Ænes de caract√®res, voici la 1√®re fonction √† appliquer afin d'√©viter toute surprise.  

Il peut arriver de rencontrer, dans d'importants jeux de donn√©es h√©t√©rog√®nes, des **variantes Unicode** comme par exemple `e\u0301cole`.  

Pour traiter ces cas on utilisera donc une m√©thode **JavaScript native**, `normalize` (que l'on appelle donc via une fonction fl√©ch√©e) avec la forme de normalisation `NFKC` (*Normalization Form Compatibility Composition*).

```js
value = get("value.entree") \
    .thru(str => str.normalize("NFKC")) \
    .replace(/\s+/g, " ") \
    .deburr()
    .toLower() \
    .trim()
// Entr√©e : "\u00E9cole" ‚Üí Sortie : "ecole"
```

---

### Supprimer les espaces superflus

Lorsque l'on r√©alise des op√©rations de nettoyage - comme par exemple enlever la ponctuation, les caract√®res sp√©ciaux etc - il peut arriver que l'on ai plusieurs espaces cons√©cutifs entre des mots. On utilisera `replace` avec une *regex* afin de remplacer ces multiples espaces par un seul.

```js
value = get("value.entree").replace(/\s+/g, " ").trim()
// Entr√©e : "Ceci      est      un       test    " ‚Üí Sortie : "Ceci est un test"
```

---

### Supprimer les caract√®res sp√©ciaux et les accents

```js
value = get("value.entree").deburr().replace(/[^a-zA-Z0-9 ]/g, "").trim()
// Entr√©e : "Eur√™ka !" ‚Üí Sortie : "Eureka"
```

---

### Supprimer les caract√®res sp√©ciaux tout en conservant les accents

```js
value = get("value.entree").replace(/[^a-zA-Z√Ä-√ñ√ò-√∂√∏-√ø0-9 ]/g, "").trim()
// Entr√©e : "Eur√™ka !" ‚Üí Sortie : "Eur√™ka"
```

---

### Nettoyer les balises et entit√©s HTML

Afin de nettoyer un texte stylis√© en HTML il convient d'abord d'utiliser `unescape` pour d√©coder les entit√©s HTML. Par exemple `&amp;` deviendra `&`.  
Puis √† l'aide d'une *regex* on supprime les balises HTML.

```js
value = get("value.entree").thru(str => _.unescape(str)) \
    .replace(/<[^>]+>/g, '')
// Entr√©e : "First lifetime investigations of <i>N</i> &gt; 82 iodine isotopes: The quest for collectivity"
// ‚Üí Sortie : "First lifetime investigations of N > 82 iodine isotopes: The quest for collectivity"
```

---

### Convertir les symboles grecs en alphabet latin

Dans de nombreux titres et r√©sum√©s apparaissent des symboles grecs, si pour des besoins de normalisation par exemple vous souhaitez les convertir, appliquer ce script.

```js
[env]
path = replaceGreeks
value = fix((title)=> \
  Object \
    .entries({ \
      'Œ±': 'alpha', \
      'Œ≤': 'beta', \
      'Œ≥': 'gamma', \
      'Œ¥': 'delta', \
      'Œµ': 'epsilon', \
      'Œ∏': 'theta', \
      'Œª': 'lambda', \
      'Œº': 'mu', \
      'œÄ': 'pi', \
      'œÉ': 'sigma', \
      'œÜ': 'phi', \
      'œâ': 'omega' \
    }) \
    .reduce( \
      (acc, [symbol, name]) => \
        acc \
          .split(symbol) \
          .join(name), \
      title \
    ) \
)
// Le script qui verbalise le symboles est stock√© dans une variale d'environnement [ENV].
// Ce qui permet de pouvoir l'utiliser plusieurs fois sur les champs title et abstract avec simplement
// .thru(env("replaceGreeks"))

[replace]
path = sortie
value = get("value.title").thru(env("replaceGreeks"))

// Entr√©e : "From Œ± to œâ."
// ‚Üí Sortie : "From alpha to omega."

```

## Exemples de transformations diverses

Ces scripts ne sont pas forc√©ment tous des cas d'usages existants, mais peuvent servir √† montrer les bonnes syntaxes √† adopter pour combiner vos fonctions.  

### G√©n√©rer une date selon les conventions fran√ßaises

La fonction **JavaScript** `new Date` permet de retourner la date et l'heure ainsi que la valeur UTC (universelle).  

```json
[
  {"doi": "10.11111"},
  {"doi": "10.22222"}
]
```

```js
[assign]
path = date
value = fix(new Date())
```

```json
[
  {"doi": "10.11111",
   "date": "2025-10-05T16:09:28.554Z"},
  {"doi": "10.22222",
   "date": "2025-10-05T16:09:28.555Z"}
]
```

Si l'on souhaite obtenir la date selon les conventions fran√ßaises (pour dater le corpus, ou une transformation) on peut ajouter une autre fonction **JavaScript** :

```js
[assign]
path = date
value = fix(new Date()) \
  .thru(d => new Intl.DateTimeFormat('fr-FR', { \
    year: 'numeric', \
    month: 'long', \
    day: 'numeric', \
  }).format(d))
```

```json
[
  {"doi": "10.11111",
   "date": "5 octobre 2025"},
  {"doi": "10.22222",
   "date": "5 octobre 2025"}
]
```

Et si l'on souhaite davantage de pr√©cisions :  

```js
[assign]
path = date
value = fix(new Date()) \
  .thru(d => new Intl.DateTimeFormat('fr-FR', { \
    timeZone: 'Europe/Paris', \
    year: 'numeric', \
    month: 'long', \
    weekday: 'long', \
    day: 'numeric', \
    hour: '2-digit', \
    minute: '2-digit', \
    second: '2-digit' \
  }).format(d))
```

:point_down:

```json
[
  {"doi": "10.11111",
   "date": "dimanche 5 octobre 2025 √† 18:20:44"},
  {"doi": "10.22222",
   "date": "dimanche 5 octobre 2025 √† 18:20:44"}
]
```

---

### Extraire l‚Äôann√©e depuis une date de publication h√©t√©rog√®ne

Dans certains jeux de donn√©es bibliographiques, le champ date de publication n‚Äôa malheureusement pas un format unique.
On peut par exemple rencontrer :
- "2023-10-25"
- "09-07-1986"
- "1986"
- "July 1986"  

Dans ce contexte, il n'est pas possible de s‚Äôappuyer sur un simple d√©coupage de la cha√Æne avec `split` suivi d‚Äôun `first` ou `last` comme on peut le faire sur des donn√©es homog√®nes.  

Pour ce faire on cherchera directement l'ann√©e, soit **quatre chiffres cons√©cutifs**, √† l'aide d'une expression r√©guli√®re et de `match`.  


```js
[assign]
path = value
value = get("value.publicationDate") \
  .thru(date => date.match(/[0-9]{4}/) ?? "aucune ann√©e trouv√©e") \
  .toString()
```

- `.match(/[0-9]{4}/)` cherche la premi√®re occurence de quatre chiffres cons√©cutifs
- `?? "aucune ann√©e trouv√©e"` petite s√©curit√© qui permet de retourner cette mention si aucune ann√©e n'est trouv√©e
- `.toString()` garantit une sortie homog√®ne sous forme de cha√Æne (si certaines valeurs √©taient en Number)

---

### Construire un tableau √† partir d‚Äôun champ et d'un autre champ transform√© pour l'occasion

Cas simple, on souhaite obtenir dans un tableau l'ann√©e de publication, la revue et l'√©diteur d'une publication.

```json
{
  "year": 2019,
  "source": "Information",
  "publisher": "Mdpi"
}
```

Mais on souhaite √©galement convertir l'ann√©e en cha√Æne (c'√©tait un nombre), mettre en minuscules la revue et en majuscules l'√©diteur. Mais **sans modifier les champs du dataset**, juste dans le cas de ce tableau.  

Plut√¥t que d'√©crire 3 enrichissements, puis de les concat√©ner, on peut r√©aliser toutes les op√©rations en un seul script.

```js
value=get("value.year").toString() \
// On r√©cup√®re l'ann√©e puis la transforme en cha√Æne
    .concat(_.toLower(self.value.source)) \
// On concat√®ne ensuite la revue que l'on met en minuscules. 
// Pour cela on place la fonction de transformation avant le nom du champ, que l'on met entre parenth√®ses pour l'occasion. 
// Et on n'oublie pas de pr√©fixer la fonction par le _ de Lodash
    .concat(_.toUpper(self.value.publisher))
// Enfin on concat√®ne le dernier champ en le transformant de la m√™me fa√ßon
```

Cependant on peut encore simplifier l'√©criture et le nombre de fonctions utilis√©es.

En utilisant `fix` on peut directement cr√©er un tableau en s√©parant les valeurs par des virgules ‚Üí `fix(selfvalueA, selfvalueB)`, on n'a donc plus besoin d'ajouter autant de `concat` que de champs.  

Ce qui donne  :

```js
value=fix(_.toString(self.value.year), _.toLower(self.value.source), _.toUpper(self.value.publisher))
// ‚Üí Sortie : ["2019","information","MDPI"]
```

---

### Construire un tableau √† partir d‚Äôun champ et d‚Äôune liste extraite d‚Äôun objet dans un autre champ

Clarifions la probl√©matique, on souhaite par exemple r√©unir en un seul tableau un *doi* et les *auteurs* associ√©s.  

Le soucis √©tant que le *doi* se trouve dans un champ (ou colonne), mais que les *auteurs* se trouvent dans un tableau d'objets d'un autre champ.

Pour visualiser, voici le dataset r√©duit √† ces deux seuls champs :

```json
[
  {
    "value": {
      "doi": "10.3390/info10050178",
      "authors": [
        {
          "fullname": "Denis Maurel",
          "affiliations": [
            "Laboratoire d‚ÄôInformatique Fondamentale et Appliqu√©e de Tours LIFAT, Bases de donn√©es et traitement des langues naturelles BDTLN, FR"
          ]
        },
        {
          "fullname": "Enza Morale",
          "affiliations": [
            "UAR76 / UPS76, Centre National de la Recherche Scientifique CNRS, Institut de l‚Äôinformation scientifique et technique INIST, 2, All√©e du Parc de Brabois, Rue Jean Zay, 54500 Vand≈ìuvre-l√®s-Nancy, FR"
          ]
        },
        {
          "fullname": "Nicolas Thouvenin",
          "affiliations": [
            "UAR76 / UPS76, Centre National de la Recherche Scientifique CNRS, Institut de l‚Äôinformation scientifique et technique INIST, 2, All√©e du Parc de Brabois, Rue Jean Zay, 54500 Vand≈ìuvre-l√®s-Nancy, FR"
          ]
        },
        {
          "fullname": "Patrice Ringot",
          "affiliations": [
            "UAR76 / UPS76, Centre National de la Recherche Scientifique CNRS, Institut de l‚Äôinformation scientifique et technique INIST, 2, All√©e du Parc de Brabois, Rue Jean Zay, 54500 Vand≈ìuvre-l√®s-Nancy, FR"
          ]
        },
        {
          "fullname": "Angel Turri",
          "affiliations": [
            "UAR76 / UPS76, Centre National de la Recherche Scientifique CNRS, Institut de l‚Äôinformation scientifique et technique INIST, 2, All√©e du Parc de Brabois, Rue Jean Zay, 54500 Vand≈ìuvre-l√®s-Nancy, FR"
          ]
        }
      ]
    }
  }
]

```

En pratique, on va cr√©er un enrichissement pour extraire les noms des *auteurs* car l'op√©ration n√©cessite un `map`, puis on fera ensuite un second enrichissement pour concat√©ner cette liste au *doi*.  

Pour faire cela en une seule √©tape, il faudrait pouvoir mapper les *auteurs* √† l'int√©rieur de `concat`. ce qui s'√©crit comme cela : 

```js
value = get("value.doi").concat(_(self.value.authors).map('fullname'))
```

Seulement, on concat√®ne ici une cha√Æne (le *doi*) √† un tableau (les *auteurs*). On obtient donc comme r√©sultat un tableau avec un tableau imbriqu√© :  
```["10.3390/info10050178",["Denis Maurel","Enza Morale","Nicolas Thouvenin","Patrice Ringot","Angel Turri"]]```

Pour obtenir un tableau √† plat, il faudrait ins√©rer des `join` et `split` (les fonctions de type `flatten` ne marcheront pas ici) mais la lecture du script sera compliqu√©e...

Au lieu de cela nous utiliserons d'abord `fix` au lieu de `get`, ceci afin de pouvoir ins√©rer un **spread operator** `...` dans la fonction.  

Nous ne d√©velopperons pas ici ce qu'est un **spread operator** ou [syntaxe de d√©composition](https://developer.mozilla.org/fr/docs/Web/JavaScript/Reference/Operators/Spread_syntax), disons simplement qu'il permet d‚Äô√©clater un tableau en ses √©l√©ments individuels afin d‚Äôobtenir un tableau plat.

Ainsi : 

```js
value = fix(self.value.doi, ...(_(self.value.authors).map('fullname')))
```

renverra : 

```["10.3390/info10050178","Denis Maurel","Enza Morale","Nicolas Thouvenin","Patrice Ringot","Angel Turri"]```  

---

### Remplacer des valeurs en fonction d'un dictionnaire de correspondance

Lorsqu‚Äôil n‚Äôy a qu‚Äôun ou deux cas, on peut tout √† fait transformer une valeur √† l‚Äôaide d‚Äôun `thru` et d‚Äôune condition ternaire `(===, ? :)`.  

Mais d√®s que les cas se multiplient, ce type d‚Äô√©criture devient :

- difficile √† lire,

- difficile √† maintenir,

- et potentiellement source d‚Äôerreurs.

Plut√¥t que d‚Äô√©crire de longues fonctions conditionnelles (ou pire, de cumuler des `replace`), il est souvent plus simple et plus lisible d‚Äôutiliser un dictionnaire de correspondance.

Dans Lodex, ce r√¥le est parfaitement rempli par l‚Äôinstruction `[env]`, qui permet de d√©finir une table de valeurs r√©utilisable dans tout le pipeline.

üëâ On remplace alors une logique conditionnelle complexe par une simple op√©ration de lookup dans un dictionnaire.

On va donc commencer par d√©finir notre table de correspondance √† l‚Äôaide de `[env]`, sous la forme d‚Äôun dictionnaire cl√© ‚Üí valeur :

```js
[env]
path = oaStatus
value = fix({ \
  "gold":   "voie dor√©e", \
  "green":  "voie verte", \
  "bronze": "voie bronze", \
  "hybrid": "voie hybride", \
  "diamond": "voie diamant", \
  "closed": "acc√®s ferm√©" \
})
```

Dans le bloc `[env]`, le param√®tre `path` permet de donner un nom √† notre table de correspondance (ou dictionnaire).
Ce nom servira ensuite √† y acc√©der n‚Äôimporte o√π dans le pipeline.  

On utilise ensuite `fix` pour d√©finir une valeur fixe, ici un objet *JavaScript*.
Chaque cl√© de cet objet correspond √† une valeur pr√©sente dans le dataset, et chaque valeur associ√©e correspond √† la valeur de remplacement souhait√©e.  

Il ne reste plus qu'√† appliquer cette table √† nos donn√©es :

```js
[
  {
    "value": {
      "entree": "gold"}},
  {
    "value": {
      "entree": "green"}},
  {
    "value": {
      "entree": ""}}
]
```

```js
[assign]
path = sortie
value = get("value.entree").thru(status => env("oaStatus")[status] ?? "statut inconnu")
```

- `get("value.entree")` on r√©cup√®re la valeur brute du dataset
- `.thru(status => env("oaStatus")[status] || "statut inconnu")`
  - on interroge le dictionnaire d√©fini dans `[env]`
  - si la cl√© existe, on r√©cup√®re la valeur correspondante
  - sinon, on renvoie une valeur par d√©faut ("statut inconnu")


:point_down:

```js
[{
    "value": {
        "entree": "gold"},
    "sortie": "voie dor√©e"},
{
    "value": {
        "entree": "green"},
    "sortie": "voie verte"},
{
    "value": {
        "entree": ""},
    "sortie": "statut inconnu"
}]
```

üí° Si dans la colonne entr√©e on a un tableau avec plusieurs valeurs, et non plus une cha√Æne de caract√®res, un simple `map` en lieu et place de `thru` remplacera toutes les valeurs du tableau.

---

### Remplacer une valeur en fonction d‚Äôun dictionnaire de correspondance via un fichier CSV distant  

Si l'on doit utiliser une table de correspondance volumineuse, il est possible de remplacer la valeur d‚Äôun champ √† partir d‚Äôun dictionnaire de correspondance (ou table d'√©quivalence) stock√© dans un fichier CSV distant. Ce dernier doit √™tre **h√©berg√© en ligne** et **accessible publiquement via une URL** (sans authentification), id√©alement en **acc√®s direct** au fichier (lien de t√©l√©chargement / lien brut). 

Dans cet exemple, on souhaite remplacer les valeurs contenues dans une colonne *typeDeDocument* gr√¢ce au fichier CSV *testTable.csv*.

| typeDeDocument | 
|----------------|
| "Article"      |
| "Art"          |

**testTable.csv**  
documentType;homogenizedType  
Article;Journal Article  
Art ;Journal Article  

On cr√©e un enrichissement dans Lodex et colle ce script :  

```js
[assign]
path = value
value = get("value.typeDeDocument")
; On s√©lectionne notre colonne Lodex √† rechercher dans le dictionnaire

[combine]
path = value
primer = https://mapping-tables.daf.intra.inist.fr/testTable.csv
; URL vers le fichier CSV accessible via internet
default = n/a
; Valeur par d√©faut si aucune correspondance n‚Äôest trouv√©e dans le dictionnaire

[combine/URLStream]
; Sert √† r√©cup√©rer le fichier distant et √† l'injecter dans le sous flux
path = false
; Sans cette ligne, EZS tente une lecture JSON.
; Avec false on lui indique de r√©cup√©rer le fichier tel quel pour le parser ensuite

[combine/CSVParse]
; C'est ici que l'on parse notre fichier CSV
separator = fix(";")
; On pr√©cise le s√©parateur du fichier CSV pour qu'il soit correctement pars√©

[combine/CSVObject]
; Cette instruction permet de transformer chaque ligne en objet
; Les cl√©s de l'objet correspondent √† la 1√®re ligne du CSV (les titres des colonnes donc)


[combine/replace]
; Avec cette instruction on construit le dictionnaire sous forme d'objet cl√© / valeur (id et value)
path = id
; On d√©finit l'identifiant de la ligne CSV
value = get("documentType")
; Colonne du CSV utilis√©e pour la correspondance (l'id sera donc par exemple "Article")

path = value
value = get("homogenizedType")
; On d√©finit les valeurs √† retourner en cas de correspondance ("Journal Article" dans notre exemple)

; Apr√®s combine on obtient donc des objets de type { "id": "Article", "value": "Journal Article" }

[exchange]
value = get("value")
; Ce dernier bloc est facultatif, il permet de ne r√©cup√©rer que le r√©sultat final √† savoir la cha√Æne "Journal Article"
```

---

### Remplacer des valeurs en fonction d‚Äôun dictionnaire de correspondance via un fichier TSV distant  

Cet exemple illustre moins le changement de format (CSV ‚Üí TSV) que la gestion des tableaux :  
comment appliquer une table de correspondance distante √† chaque valeur d‚Äôune liste en appliquant un traitement it√©ratif.  

On cherchera ici √† verbaliser les donn√©es de la colonne *countryCode* √† l'aide du fichier TSV *Pays_test.tsv*

| countryCode | 
|-------------|
| ["BE","FR"] |
| ["IT"]      |

**Pays_test.tsv**
From	To  
BE	Belgium  
FR	France  
IT	Italy  

```js
[assign]
path = value
value = get("value.countryCode")

[map]
path = value
; Sert √† traiter individuellement chaque valeur de la liste (chaque code ici)

[map/replace]
path = tempkey
value = self()
; Cr√©ation d'une cl√© temporaire pour stocker la valeur actuelle

[map/combine]
path = tempkey
primer = https://mapping-tables.daf.intra.inist.fr/Pays_test.tsv
; URL vers un fichier TSV accessible via internet
default = n/a

[map/combine/URLStream]
path = false

[map/combine/CSVParse]
separator = fix("\t")
; On pr√©cise ici que le s√©parateur est une tabulation

[map/combine/CSVObject]

[map/combine/replace]
path = id
value = get('From')
path = value
value = get('To')
; Une fois le TSV pars√© en objets JSON, la valeur de "From" est transform√© en cl√©
; et celle de "To" en valeur ({"From": "FR", "To": "France"})

; On r√©cup√®re donc ceci [{"tempkey":{"id":"BE","value":"Belgium"}},{"tempkey":{"id":"FR","value":"France"}}]

[map/exchange]
value = get('tempkey.value')
; Extraction de la valeur finale
```
---

### Remplacer des valeurs en fonction d'un dictionnaire de correspondance via un fichier JSONL distant

Apr√®s avoir vu l‚Äôutilisation de fichiers TSV comme tables de correspondance, nous allons maintenant nous int√©resser au format JSONL (JSON Lines).  

Le JSONL est particuli√®rement pratique dans l‚Äô√©cosyst√®me Lodex, car :
- chaque ligne est un objet JSON autonome
- il est facilement lisible et traitable en streaming
- Lodex exporte naturellement ses donn√©es au format JSONL, **ce qui permet de r√©utiliser directement les donn√©es d‚Äôun autre Lodex comme table de correspondance.**  

**Cas d‚Äôusage : enrichir une notice contenant plusieurs RNSR avec les laboratoires associ√©s**

On dispose d‚Äôun premier Lodex qui joue le r√¥le de dictionnaire :
- une colonne rnsr
- une colonne laboratoires

On exporte ces deux colonnes en JSONL (format d‚Äôexport Lodex).
Chaque ligne du JSONL correspondra donc √† une entr√©e du dictionnaire :  

**tableRnsrLaboratoire.jsonl**

{"rnsr":"200918450V","laboratoire":"Institut des sciences de la Terre Paris"}
{"rnsr":"199812866Y","laboratoire":"Laboratoire de g√©ologie de l'Ecole Normale Sup√©rieure"}

Dans notre jeu de donn√©es (un second Lodex), chaque notice peut contenir plusieurs RNSR (un tableau de valeurs).
Pour chaque notice, on voudra donc r√©cup√©rer l‚Äôensemble des laboratoires correspondant √† chacun des RNSR.

| codesRnsr                   | 
|-----------------------------|
| ["200918450V"]              |
| ["199812866Y","200918450V"] |

:point_down:

```js
[assign]
path = value
value = get("value.codesRnsr")

[map]
path = value

[map/replace]
path = tmpkey
value = self()

[map/combine]
path = tmpkey
primer = https://mapping-tables.daf.intra.inist.fr/tableRnsrLaboratoire.jsonl
default = n/a

[map/combine/URLStream]
path = false

[map/combine/unpack]
; On utilise ici l'instruction unpack pour lire et traiter le fichier ligne par ligne

[map/combine/replace]
path = id
value = get('rnsr')
path = value
value = get("laboratoire")

[map/exchange]
value = get("tmpkey.value")
```

---

### Importer des donn√©es pr√©-calcul√©es dans le dataset

Dans Lodex, certains traitements peuvent √™tre ex√©cut√©s **en dehors du dataset principal**, sous forme de **pr√©-calculs**.  
Ces pr√©-calculs sont stock√©s s√©par√©ment et ne modifient pas directement les notices du jeu de donn√©es.  

Certains pr√©-calculs produisent des r√©sultats globaux √† l'√©chelle du corpus, d'autres sont **li√©s aux notices** et renvoient donc explicitement les identifiants (id) des documents concern√©s.  

Pour ce dernier cas, il est possible de r√©cup√©rer ces r√©sultats via un enrichissement afin de les injecter dans le dataset.  

Cela permet de les exploiter ensuite comme n'importe quelle autre colonne : 
- champs de ressource
- facettes
- graphiques divers  

**Structure des r√©sultats de pr√©-calcul**  

Les r√©sultats d'un pr√©-calcul sont des **objets JSON** ayant la forme suivante :  

```js
{
  "id": "uid:/iSZ2QaTPJ",
  "value": [
    "Security",
    "methodology",
    "mobile devices",
    "wide variety",
    "constraints"
  ],
  "lodexStamp":{
    "importedDate":"Sun Jan 25 2026",
    "precomputedId":"69767dc39bfb77f07861fffd",
    "webServiceURL":"https://data-homogenise.services.istex.fr/v1/homogenise?sid=lodex"}
}
```

Afin de r√©cup√©rer les r√©sultats stock√©s dans `value` on √©crira ce script dans un enrichissement :  

```js
[assign]
path = value
value = get("id")
; On remplace la valeur courante par l‚Äôidentifiant unique de chaque notice 
; C‚Äôest cette cl√© qui permet de retrouver les donn√©es pr√©-calcul√©es correspondantes.

[expand]
path = value

[expand/precomputedSelect]
name = homogeniseKeywords
; On indique ici la source √† interroger, soit le nom que l'on a attribu√© au pr√©-calcul
filter = fix({id: self.value})
; On filtre pour ne r√©cup√©rer que la partie du JSON associ√©e √† la notice

[expand/aggregate]

[exchange]
value = get("value")
; Enfin, on ne conserve que les r√©sultats stock√©s dans la cl√© value du pr√©-calcul
```

> [!NOTE]
> Il est possible de se passer du dernier bloc `[exchange]`.  
> Dans ce cas, l‚Äôenrichissement renverra les **objets JSON complets** issus du pr√©-calcul (tels que pr√©sent√©s plus haut),  
> et non uniquement la valeur extraite.

---

### Tronquer les titres issus d'un pr√©-calcul topRefExtract

Le pr√©-calcul topRefExtract produit initialement un graphe au format GEXF, utilis√© pour la visualisation, ce graphe est ensuite traduit en JSON comme cet exemple :  

```JSON
    {
        "id": "https://doi.org/10.1098/rspb.2000.1204",
        "value": {
            "label": "Fragile transmission cycles of tick-borne encephalitis virus may be disrupted by predicted climate change",
            "viz$color": {
                "r": "0",
                "g": "0",
                "b": "255",
                "a": "0.8"
            },
            "viz$size": {
                "value": "50.0"
            },
            "targets": [
                {
                    "id": "https://doi.org/10.1126/science.289.5485.1763"
                }
            ]
        },
        "attributes": {
            "count": "0",
            "statut": "citant",
            "title": "Fragile transmission cycles of tick-borne encephalitis virus may be disrupted by predicted climate change"
        },
        "lodexStamp": {
            "importedDate": "Fri Jan 30 2026",
            "precomputedId": "697c63e6e9d4b0e5e69d3a6b",
            "webServiceURL": "https://data-topcitation.services.istex.fr/v1/topcitation?nbCitations=4&sid=lodex"
        }
    }
```

Pour des raisons d‚Äôaffichage du graphe, les titres des documents contenus dans le champ `label` de `value` peuvent s‚Äôav√©rer trop longs.  
Afin d‚Äôam√©liorer la lisibilit√© du graphe, il est possible de tronquer ces titres.  

Le graphe est construit √† partir des donn√©es contenues dans les cl√©s `id` et `value` des objets issus du pr√©-calcul.  
Il est donc n√©cessaire de reconstruire un objet `value` similaire √† celui produit par le pr√©-calcul, en ne modifiant que le champ `label` (le titre du document). Les autres propri√©t√©s de `value` sont reprises telles quelles afin de pr√©server la structure et les m√©triques utilis√©es par le graphe

Pour ce faire, on cr√©e donc un enrichissement en mode avanc√© en s√©lectionnant comme source de donn√©es notre pr√©-calcul, puis on applique ce script :  

```js
[assign]
path = value
value = get("value.value").thru(obj => \
  ({ \
    ...obj, \
    label: ( \
      typeof obj.label === "string" && obj.label.length > 35 \
        ? _.truncate(obj.label, { length: 35 }) \
        : obj.label \
    ) \
  }) \
)
```

- `...obj` garantit que toutes les propri√©t√©s de l‚Äôobjet value sont conserv√©es
- `typeof obj.label === "string" && obj.label.length > 35` **si** la valeur de label est une cha√Æne de caract√®reset **et si** sa longueur est sup√©rieure √† 35 caract√®res
- `_.truncate(obj.label, { length: 35 })` alors on applique une troncature (qui ajoute automatiquement `...` √† la fin de la cha√Æne)

On obtient alors notre nouvel objet :

```JSON
    {
        "id": "https://doi.org/10.1098/rspb.2000.1204",
        "value": {
            "label": "Fragile transmission cycles of tick-borne encephalitis virus may be disrupted by predicted climate change",
            "viz$color": {
                "r": "0",
                "g": "0",
                "b": "255",
                "a": "0.8"
            },
            "viz$size": {
                "value": "50.0"
            },
            "targets": [
                {
                    "id": "https://doi.org/10.1126/science.289.5485.1763"
                }
            ]
        },
        "attributes": {
            "count": "0",
            "statut": "citant",
            "title": "Fragile transmission cycles of tick-borne encephalitis virus may be disrupted by predicted climate change"
        },
        "lodexStamp": {
            "importedDate": "Fri Jan 30 2026",
            "precomputedId": "697c5509e9d4b0e5e69d3a68",
            "webServiceURL": "https://data-topcitation.services.istex.fr/v1/topcitation?nbCitations=4&sid=lodex"
        },
        "enrichedValue": {
            "label": "Fragile transmission cycles of t...",
            "viz$color": {
                "r": "0",
                "g": "0",
                "b": "255",
                "a": "0.8"
            },
            "viz$size": {
                "value": "50.0"
            },
            "targets": [
                {
                    "id": "https://doi.org/10.1126/science.289.5485.1763"
                }
            ]
        }
    }
```

## Transformations globales (dans le cadre d'un loader)

### Num√©roter les lignes de son dataset
  
Il peut √™tre utile, pour retrouver certaines donn√©es, d'avoir un corpus num√©rot√©. Pour cela on peut utiliser la fonction `uniqueId` et customiser notre identifiant pour mieux s'adapter √† nos besoin.  

Ici par exemple, pour un corpus de donn√©e de plusieurs centaines de milliers de documents, on cr√©e un champ *line* √† 6 chiffres :

```json
[ 
  {"doi": "10.11111"},
  {"doi": "10.22222"},
  {"doi": "10.33333"},
  {"doi": "10.44444"},
  {"doi": "10.99999"}
]
```

```js
[assign]
path = line
value = fix("").uniqueId().padStart(6, "0")
```

:point_down:

```json
[
  {"doi": "10.11111",
   "line": "000001"},
  {"doi": "10.22222",
   "line": "000002"},
  {"doi": "10.33333",
   "line": "000003"},
  {"doi": "10.44444",
   "line": "000004"},
  {"doi": "10.99999",
   "line": "000005"}
]
```

üí° On peut √©galement mettre cet identifiant unique en guise d'uri :

```js
[assign]
path = uri
value = fix("").uniqueId().padStart(6, "0")
```

---

### D√©doublonner des lignes parfaitement identiques

Dans certains jeux de donn√©es, on ne dispose pas de champ discriminant clair (comme un DOI ou autre identifiant unique) qui permet de d√©tecter et supprimer les doublons.  

Dans ces situations, la seule solution consiste √† comparer l‚Äôobjet entier. Si deux lignes sont strictement identiques, l‚Äôune d‚Äôelles doit √™tre supprim√©e.  

Or, deux objets JavaScript identiques peuvent √™tre difficiles √† comparer directement, surtout dans un flux de donn√©es.  
La seule solution consiste √† g√©n√©rer une **empreinte unique** de chaque objet, puis √† d√©doublonner sur cette empreinte.  

Pour ce faire, il faut utiliser un **SHA** *(Secure Hash Algorithm)*.  
C'est une fonction de hachage cryptographique qui transforme une donn√©e (texte, nombre, objet JSON‚Ä¶) en une empreinte num√©rique unique (une longue cha√Æne de caract√®res).  
*(Si vous souhaitez en connaitre davantage sur ce point, je vous conseille cet excellent [livre](https://www.deboecksuperieur.com/livre/9782807345331-les-algorithmes-c-est-plus-simple-avec-un-dessin)).*

Il faut donc appliquer une fonction SHA √† chaque ligne de son dataset pour pouvoir d√©doublonner.

D√©monstration :

```json
[
  { "a": 1, "b": 2 },
  { "a": 2, "b": 3 },
  { "a": 1, "b": 2 }
]
```

```js
[assign]
; On met l'objet complet dans un champ hash
path = hash
value = self().cloneDeep().thru(obj => _(obj).toPairs().sortBy(0).fromPairs().value())
; Par s√©curit√© on copie un objet propre pour √©viter les r√©f√©rences circulaires et on trie ses cl√©s par ordre alphab√©tique

[map]
; On "pr√©pare" le champ hash pour lui appliquer plusieurs transformations sp√©cifiques
path = hash

[map/identify]
; On g√©n√®re un identifiant SHA
scheme = sha
path = hash

[map/exchange]
value = get('hash')
```

A cette √©tape du script on a bien g√©n√©r√© des empreintes num√©riques dans le champ *hash* :

```json
[{
    "a": 1,
    "b": 2,
    "hash": [
        "sha:/43258cff783fe7036d8a43033f830adfc60ec037382473548ac742b888292777z"
    ]
},
{
    "a": 2,
    "b": 3,
    "hash": [
        "sha:/206f7b5543e6f2ef39bf334988fd7097b725caeed16588cd9d785480f2f0f8f6S"
    ]
},
{
    "a": 1,
    "b": 2,
    "hash": [
        "sha:/43258cff783fe7036d8a43033f830adfc60ec037382473548ac742b888292777z"
    ]
}]
```

Ne reste plus qu'√† d√©doublonner et √©ventuellement enlever le champ *hash* qui a jou√© son r√¥le.

```js
[dedupe]
path = hash
ignore = true

[exchange]
value = omit("hash")
```

:point_down:

```json
[
  {"a":1,"b":2},
  {"a":2,"b":3}
]
```

---

### Trier les colonnes de son dataset par ordre alphab√©tique

```json
[
  {
    "title": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
    "authors": [
      "Carine Bach",
      "Lucile Bourguignon",
      "Christa Gu√©l√©",
      "Philippe Houdry",
      "Ana√´l Kremer"
    ],
    "document_type": "Working Paper",
    "year": 2025,
    "abstract": "En d√©cembre 2023, le MESR a mis en place un partenariat pluriannuel avec OpenAlex. En janvier 2024, le CNRS annonce se d√©sabonner de Scopus...",
    "keywords": [
      "OpenAlex",
      "bibliom√©trie"
    ]
  }
]
```

```js
[exchange]
value = self() \
    .toPairs() \
    .sortBy(0) \
    .fromPairs() 
```

On utilise √©videmment `[exchange]` pour remplacer le dataset d'origine par notre dataset transform√©.  

- `self` pour travailler sur tout l'objet courant,  
- `toPairs` transforme l'objet en un tableau de paires cl√©/valeur => `["document_type", "Working Paper"],["year", 2025]...`,
- `sortBy(0)` trie le tableau par le premier √©l√©ment de chaque paire (donc la cl√©),
- `fromPairs` reconstruit l'objet.

```json
[{
    "abstract": "En d√©cembre 2023, le MESR a mis en place un partenariat pluriannuel avec OpenAlex. En janvier 2024, le CNRS annonce se d√©sabonner de Scopus...",
    "authors": [
        "Carine Bach",
        "Lucile Bourguignon",
        "Christa Gu√©l√©",
        "Philippe Houdry",
        "Ana√´l Kremer"
    ],
    "document_type": "Working Paper",
    "keywords": [
        "OpenAlex",
        "bibliom√©trie"
    ],
    "title": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
    "year": 2025
}]
```

---

### Supprimer des pr√©fixes ou suffixes dans des noms de colonnes.  

Il arrive fr√©quemment que les colonnes d‚Äôun dataset contiennent des pr√©fixes ou suffixes parasites. Par exemple : 

```json
[{
  "metaTitle": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
  "metaDocument_type": "Working Paper",
  "metaYear": 2025
}]
```

```js
[exchange]
value = self().mapKeys((value, key) => \
    _.startsWith(key, "meta") \
        ? key.slice(4) \
        : key \
)
```

- `mapKeys` permet d'appliquer une fonction √† toutes les cl√©s d'un objet,
- `.startsWith(key, "meta")` permet de ne capturer que les cl√©s commen√ßant par "meta",
- `key.slice(4)` supprime les 4 premiers caract√®res de ces cl√©s, donc meta,
- `: key` renvoie toutes les autres cl√©s inchang√©es.

```json
[{
    "Title": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
    "Document_type": "Working Paper",
    "Year": 2025
}]
```

Si l'on souhaite supprimer des suffixes, on utilisera `endsWith` en lieu et place de `startsWith` et modifiera `slice` pour supprimer les derniers caract√®res cette fois.

```js
[exchange]
value = self().mapKeys((value, key) => \
    _.endsWith(key, "_old") \
        ? key.slice(0,-4) \
        : key \
)
```

---

### Standardiser des noms de colonnes.

Si vous vous souvenez des "bonnes pratiques" [√©nnonc√©es](https://github.com/AnaelKremer/Atelier-Lodash-usage-Lodex/blob/main/03-syntaxe-et-bonnes-pratiques.md#le-nommage-des-colonnesenrichissements) au d√©but de ce parcours, vous savez qu'il est important d'avoir des colonnes nomm√©es correctement.  

Mais souvent on doit faire avec ce que l'on a... 

On a d√©j√† vu comment nettoyer des cha√Ænes de caract√®res, en combinant `mapKeys` √† `[exchange]` on peut appliquer ces transformations √† toutes les colonnes du datatset !  

```json
[
  {
    "_is_oa_?": true,
    "_publication_year": 2025,
    "_author_affiliations": "CNRS"
  }
]

```

```js
[exchange]
value = self().mapKeys((value, key) => \
    _.camelCase( \
        _.deburr(key) \
          .replace(/[^a-zA-Z0-9_ ]/g, "") \
    ) \
)
```

- `mapKeys` pour it√©rer sur toutes les cl√©s d'un objet,
- `camelCase` qui applique la convention de nommage du m√™me nom,
- `deburr` pour enlever les accents,
- `replace` avec une *regex* pour retirer la ponctuation ou caract√®res sp√©ciaux.

:point_down:

```json
[{
    "isOa": true,
    "publicationYear": 2025,
    "authorAffiliations": "CNRS"
}]
```

---

### Normaliser un dataset issu d'un parsing XML

Il peut arriver que certaines sources de donn√©es produisent des champs **structur√©s sous forme d‚Äôobjets**, plut√¥t que des valeurs simples.  
C‚Äôest notamment le cas lorsque des donn√©es issues de formats riches (comme le XML) sont converties en JSON : le contenu textuel et les m√©tadonn√©es associ√©es (langue, type, etc.) sont alors s√©par√©s.  

On peut par exemple rencontrer des champs de la forme :  

```JSON
{
  "source": "HAL",
  "title": {
    "type": "string",
    "xmlLang": "fr",
    "value": "bla bla bla"
  },
  "year": {
    "type": "number",
    "value": 2023
  }
}
```

Dans Lodex, ce niveau de structuration est souvent inutile, il ajoute de la complexit√© et augmente le volume de donn√©es √† stocker.  
On peut facilement restructurer l'int√©gralit√© du jeu de donn√©es via ce script :

```js
[exchange]
value = self().mapValues(v => _.get(v, 'value', v))
```

- On utilise `[exchange]` pour remplacer tout l'objet d'origine
- On pointe sur `self` pour manipuler l'objet complet
- `mapValues` va appliquer une transformation √† **chaque valeur**, cl√© par cl√©
- `_.get(v, 'value', v)` 
  - Si la valeur du champ est un objet et qu‚Äôil poss√®de une propri√©t√© *value*, on retourne la valeur associ√©e
  - Si la valeur du champ est d√©j√† une valeur simple (string, nombre) on la retourne telle quelle

On obtient alors :

```JSON
{
  "source": "HAL",
  "title": "bla bla bla",
  "year": 2023
}
```

---

### Transformer les valeurs de type cha√Ænes de caract√®res de plusieurs colonnes

On peut transformer les valeurs de plusieurs colonnes √† l'aide `mapValues` et `[exchange]` en s√©lectionnant les colonnes √† transformer :

```json
[
  {
    "title": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
    "authors": [
"Carine Bach", "Lucile Bourguignon", "Christa Gu√©l√©", "Philippe Houdry", "Ana√´l Kremer"],
    "document_type": "Working Paper",
    "year": 2025,
    "abstract": "En d√©cembre 2023, le MESR a mis en place un partenariat pluriannuel avec OpenAlex. En janvier 2024, le CNRS annonce se d√©sabonner de Scopus...",
    "keywords": ["OpenAlex", "bibliom√©trie"]
  }
]
```

```js
[exchange]
value = self().mapValues( \
    (value, key) => \
        ['title', 'abstract','document_type'].includes(key) \
            ? _.toLower(_.deburr(_.trim(value))) \
            : value \
)
```

- `mapValues` applique une transformation √† toutes les valeurs de l‚Äôobjet, cl√© par cl√©,
- `includes(key)` ne transforme que si la cl√© fait partie de la liste ['title', 'abstract','document_type'],
- `deburr` supprime les accents et diacritiques (√© ‚Üí e),
- `trim` supprime les espaces superflus au d√©but et √† la fin de la cha√Æne,
- `toLower` convertit tout le texte en minuscules.

:point_down:

```json
[{
    "title": "bibliometrie prete a l'emploi avec openalex : retour d'experience",
    "authors": [
        "Carine Bach",
        "Lucile Bourguignon",
        "Christa Gu√©l√©",
        "Philippe Houdry",
        "Ana√´l Kremer"
    ],
    "document_type": "working paper",
    "year": 2025,
    "abstract": "en decembre 2023, le mesr a mis en place un partenariat pluriannuel avec openalex. en janvier 2024, le cnrs annonce se desabonner de scopus...",
    "keywords": [
        "OpenAlex",
        "bibliom√©trie"
    ]
}]
```

üí° On peut √©galement √©tendre les transformations √† **tous les champs de type string** !

```js
[exchange]
value = self().mapValues( \
    (value) => \
        _.isString(value) \
            ? _.toLower(_.deburr(_.trim(value))) \
            : value \
)
```

L'utilisation de `isString` ici permet d'appliquer les fonction √† tous les champs ayant des donn√©es de type string sans devoir s√©lectionner tous les champs manuellement.

---

### Transformer des valeurs dans des tableaux pour plusieurs colonnes

Ici on va appliquer nos transformations uniquement √† des tableaux, et seulement si les valeurs de ces tableaux sont des strings : 

```json
[
  {
    "title": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
    "authors": [
      "Carine Bach",
      "Lucile Bourguignon",
      "Christa Gu√©l√©",
      "Philippe Houdry",
      "Ana√´l Kremer"
    ],
    "des bool√©ens": [
      true,
      false,
      true
    ],
    "year": 2025,
    "keywords": [
      "OpenAlex",
      "bibliom√©trie"
    ]
  }
]
```

```js
[exchange]
value = self().mapValues( \
    (value, key) => \
        _.isArray(value) \
            ? value.map(v => _.isString(v) ? _.capitalize(_.deburr(_.trim(v))) : v) \
            : value \
)
```

Cela s'√©crit de la m√™me fa√ßon que dans l'exemple pr√©c√©dent, on ajoute seulement une nouvelle condition avec `isArray` et un `map` pour it√©rer sur chaque √©l√©ment des tableaux.

```json
[{
    "title": "Bibliom√©trie pr√™te √† l'emploi avec OpenAlex : retour d'exp√©rience",
    "authors": [
        "Carine bach",
        "Lucile bourguignon",
        "Christa guele",
        "Philippe houdry",
        "Anael kremer"
    ],
    "un tableau de bool√©ens": [
        true,
        false,
        true
    ],
    "year": 2025,
    "keywords": [
        "Openalex",
        "Bibliometrie"
    ]
}]
```

On constate que tous les champs n'√©tant pas des tableaux n'ont pas √©t√© impact√©s, et que le champ *des bool√©ens* qui ne contenait pas de strings n'a pas √©t√© transform√© non plus.  
Seuls les tableaux *authors* et *keywords* ont √©t√© modifi√©s.

---

### Transformer des champs en tableaux √† partir de cha√Ænes d√©limit√©es

On peut rencontrer dans certains jeux de donn√©es des champs contenant plusieurs valeurs sous forme de cha√Ænes avec un s√©parateur.  
Cela peut facilmeent √™tre transform√© en tableaux :

```json
[
  {
    "authors": "Carine Bach;Lucile Bourguignon;Christa Gu√©l√©;Philippe Houdry;Ana√´l Kremer",
    "year": 2025,
    "keywords": "OpenAlex;bibliom√©trie"
  }
]
```

Toujours les c√©l√®bres `mapValues` et `includes`, il suffit esnuite de splitter les champs avec le bon s√©parateur.

```js
[exchange]
value = self().mapValues((value, key) => \
  ['authors', 'keywords'].includes(key) \
    ? _.split(value, ';') \
    : value \
)
```

:point_down:

```json
[{
    "authors": [
        "Carine Bach",
        "Lucile Bourguignon",
        "Christa Gu√©l√©",
        "Philippe Houdry",
        "Ana√´l Kremer"
    ],
    "year": 2025,
    "keywords": [
        "OpenAlex",
        "bibliom√©trie"
    ]
}]
```

---

### Trier les lignes du dataset en fonction d'un champ

On souhaite, par exemple, r√©organiser son dataset selon le `nom` et par ordre alphab√©tique.

```json
[
  { "nom": "Dupont", "prenom": "Bob" },
  { "nom": "Martin", "prenom": "Zoe" },
  { "nom": "Dupont", "prenom": "Alice" },
  { "nom": "Martin", "prenom": "Alex" }
]
```

```js
[sort]
path = nom
```

:point_down:

```json
[{
    "nom": "Dupont",
    "prenom": "Bob"
},
{
    "nom": "Dupont",
    "prenom": "Alice"
},
{
    "nom": "Martin",
    "prenom": "Zoe"
},
{
    "nom": "Martin",
    "prenom": "Alex"
}]
```

> [!TIP]
> On peut inverser le tri en ajoutant simplement 
> `reverse = true`

---

### Trier les lignes du dataset en fonction de plusieurs champs

Pour le m√™me exemple, on souhaiterait affiner le tri. Si le m√™me nom est pr√©sent plusieurs fois, on classe par pr√©nom et par ordre alphab√©tique.

```json
[
  { "nom": "Dupont", "prenom": "Bob" },
  { "nom": "Martin", "prenom": "Zoe" },
  { "nom": "Dupont", "prenom": "Alice" },
  { "nom": "Martin", "prenom": "Alex" }
]
```

Il est n√©cessaire de mettre 2 fois l'instruction, et on fait bien attention √† l'ordre des instructions. Du plus fin au plus g√©n√©ral. 

```js
[sort]
path = prenom

[sort]
path = nom
```

:point_down:

```json
[{
    "nom": "Dupont",
    "prenom": "Alice"
},
{
    "nom": "Dupont",
    "prenom": "Bob"
},
{
    "nom": "Martin",
    "prenom": "Alex"
},
{
    "nom": "Martin",
    "prenom": "Zoe"
}]
```

---

### Eclater puis fusionner des donn√©es

Ce type de manipulation est utile lorsqu‚Äôon veut **changer la logique d‚Äôorganisation** d‚Äôun dataset :  
passer d‚Äôun format ¬´ une ligne par publication ¬ª √† un format ¬´ une ligne par affiliation ¬ª, par exemple.  

Prenons un jeu de donn√©es o√π figurent des publications et les affiliations associ√©es :   

| doi | affiliations   |
|------------|-----------------------------------|
| 10.11111   | laboratoire A ; laboratoire B     |
| 10.22222   | laboratoire B ; laboratoire C     |

Soit l'objet : 

```json
[
  {
    "doi": "10.11111",
    "affiliations": ["laboratoire A", "laboratoire B"]
  },
  {
    "doi": "10.22222",
    "affiliations": ["laboratoire B", "laboratoire C"]
  }
]
```

On souhaiterais r√©organiser le jeu de donn√©es de sorte √† obtenir une ligne pour chaque affiliation avec les publications associ√©es, soit :  

| affiliations | doi       |
|---------------------------------|--------------------|
| laboratoire A                   | 10.11111           |
| laboratoire B                   | 10.11111 ; 10.22222|
| laboratoire C                   | 10.22222           |

Il va donc falloir dans un premier temps multiplier les lignes √† partir des affiliations. Pour cela, 3 petites lignes suffisent.  

```js
[exploding]
id = doi
value = affiliations
```

On obtient d√©sormais ceci :

```json
[{
    "id": "10.11111",
    "value": "laboratoire A"
},
{
    "id": "10.11111",
    "value": "laboratoire B"
},
{
    "id": "10.22222",
    "value": "laboratoire B"
},
{
    "id": "10.22222",
    "value": "laboratoire C"
}]
```

On notera qu‚Äô√† cette √©tape, nous avons perdu les noms de nos champs d‚Äôorigine :
- les doi sont d√©sormais contenus dans la cl√© `id`,
- les affiliations se trouvent dans la cl√© `value`.  

Avant d‚Äôutiliser `[aggregate]`, il faut donc inverser cette logique :
- placer les affiliations (actuellement dans `value`) dans `id`,
- mettre les DOIs (actuellement dans `id`) dans `value`.

Cela se fait en quelques lignes :

```js
[replace]
path = id
value = get("value")

path = value
value = self().omit("value")

[aggregate]
path = id
```

Les donn√©es sont maintenant agr√©g√©es mais il faut encore reconstruire l'objet :  

```json
[{
    "id": "laboratoire A",
    "value": [
        {
            "id": "10.11111"
        }
    ]
},
{
    "id": "laboratoire B",
    "value": [
        {
            "id": "10.11111"
        },
        {
            "id": "10.22222"
        }
    ]
},
{
    "id": "laboratoire C",
    "value": [
        {
            "id": "10.22222"
        }
    ]
}]
```

On renomme donc les cl√©s pour r√©cup√©rer les noms explicites.  

- On change donc le nom de la cl√© `id` en `affiliation`
- On cr√©e une cl√© `doi` o√π l'on r√©cup√®re toutes les valeurs des champs `id`, eux m√™mes contenus dans `value`.

```js
[exchange]
value = fix({ \
  affiliation: self.id, \
  doi: _.map(self.value, "id") \
})
```

:point_down: R√©sultat final :

```json
[{
    "affiliation": "laboratoire A",
    "doi": [
        "10.11111"
    ]
},
{
    "affiliation": "laboratoire B",
    "doi": [
        "10.11111",
        "10.22222"
    ]
},
{
    "affiliation": "laboratoire C",
    "doi": [
        "10.22222"
    ]
}]
```