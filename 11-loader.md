# Traitements avancÃ©s dans un loader

## Quâ€™est-ce quâ€™un loader dans Lodex ?

Dans **Lodex**, un loader est un fichier de configuration permettant d'importer un jeu de donnÃ©es dans une instance.  

Son rÃ´le est de convertir **un fichier brut** (CSV, JSON, XML, etc.) en un flux dâ€™objets **JavaScript** prÃªts Ã  Ãªtre stockÃ©s dans **la base MongoDB de Lodex**.  

```mermaid
graph TD;
  A["Fichier brut (CSV, JSON, XML...)"] --> B["Loader (script EZS)"];
  B --> C["Objets JavaScript"];
  C --> D["Base MongoDB (Lodex)"];
```

Un loader s'Ã©crit dans un **fichier `.ini`**.  
- `.ini` = *Initialization file* (fichier dâ€™initialisation).  
- Historiquement, ce format sert Ã  dÃ©crire des configurations sous forme texte, avec des **sections** (`[ ]`) et des paires `clÃ© = valeur`.  
- Lodex rÃ©utilise ce format pour dÃ©crire un **pipeline de transformation**.  

Un fichier `.ini` suit une logique d'Ã©tapes : il est lu de haut en bas et est exÃ©cutÃ© sÃ©quentiellement.  
Chaque section Ã©tant une Ã©tape du pipeline qui applique une transformation au flux de donnÃ©es avant de le transmettre Ã  la suivante.  

ðŸ‘‰ Exemple :  

```ini
[assign]
path = Unpaywall
value = get("Identifiers.DOI")

[swing]
test = get("Unpaywall").isEmpty()
reverse = true

[swing/expand]
path = Unpaywall
size = 100

[swing/expand/URLConnect]
url = https://biblio-tools.services.istex.fr/v2/unpaywall/works/expand
timeout = 3600000
noerror = false
retries = 5
```

ðŸ” Explications :

```txt
        [assign]    â†’ crÃ©ation du champ "Unpaywall" Ã  partir du champ "DOI"
           â”‚
           â–¼
        [swing]     â†’ On teste si le champ est vide (absence de DOI), si c'est le cas on exclue ces donnÃ©es du traitement
           â”‚
           â–¼
     [swing/expand]     â†’ On regroupe les donnÃ©es par paquet de 100
           â”‚
           â–¼
 [swing/expand/URLConnect]    â†’ On interroge lâ€™API Unpaywall
           â”‚
           â–¼
 On rÃ©cupÃ¨re les information d'Unpaywall dans notre champ
```

Ce modÃ¨le en **pipeline** rend les loaders trÃ¨s **flexibles** : on peut ajouter, retirer ou modifier des Ã©tapes sans casser lâ€™ensemble.  

---

Ecrire ses transformations dans un *loader* plutÃ´t que dans **Lodex** en *enrichissements* prÃ©sente plusieurs avantages :  

- Tout d'abord, **Lodex** fonctionne en **stream** :
  - Lorsquâ€™on applique des enrichissements, Lodex travaille par paquets.  
  - Chaque paquet est transformÃ©, envoyÃ© dans MongoDB, puis relu pour passer Ã  lâ€™Ã©tape suivante.
  - Cela provoque de nombreux allers-retours entre Lodex et MongoDB, ce qui rallonge les temps de traitement.
- Un loader agit diffÃ©remment :
  - Le fichier est lu et transformÃ© Ã©tape par Ã©tape dans le pipeline EZS.  
  - Toutes les transformations sont effectuÃ©es **avant** lâ€™Ã©criture en base.
  - Puis le flux final dâ€™objets JavaScript est envoyÃ© en une seule fois Ã  MongoDB.
- Et surtout, un loader permet de rÃ©aliser des opÃ©rations impossibles ou limitÃ©es dans Lodex:
  - **Lodex** traite chaque "notice" indÃ©pendamment (*ou ligne par ligne)*.
  - Un loader peut lire et transformer tout le dataset Ã  la fois, ce qui rend possibles des opÃ©rations globales comme :
    - dÃ©doublonner des lignes entiÃ¨res (*notices identiques*),
    - fusionner des donnÃ©es,
    - ou appliquer des transformations lourdes sur lâ€™ensemble.  

ðŸ“Œ **En rÃ©sumÃ©, Lodex traite les donnÃ©es ligne par ligne et nous pousse Ã  raisonner notice par notice, tandis quâ€™un loader permet de rÃ©flÃ©chir en termes dâ€™opÃ©rations globales sur lâ€™ensemble du dataset, ce qui en augmente considÃ©rablement le potentiel de transformation.**

---

Pour qu'un loader fonctionne correctement, il faut inclure des instructions **EZS** spÃ©cifiques (comme `[unpack]`, `[identify]`, `[OBJFlatten]`â€¦) et dÃ©clarer des *plugins*, mais ce n'est pas l'objet de cette documentation.  

Ces aspects techniques relÃ¨vent davantage dâ€™une formation dÃ©diÃ©e Ã  **EZS**, Ã§a tombe bien ! Mon collÃ¨gue FranÃ§ois Parmentier en a justement fait une [ici](https://github.com/parmentf/formation-ezs/tree/master).  

Nous allons nous concentrer ici sur un ensemble restreint dâ€™instructions essentielles pour transformer et nettoyer les donnÃ©es avec Lodash.  

## Les instructions EZS

### [assign]

`[assign]` permet d'affecter une valeur Ã  un champ de l'objet courant. Si le champ existe dÃ©jÃ , sa valeur est Ã©crasÃ©e, sinon il est crÃ©Ã©.

```json
[{
    "DO": "10.3390/info10050178 ",
    "TI": "Istex: A Database of Twenty Million Scientific Papers with a Mining Tool Which Uses Named Entities",
    "SO": "Information"
}]
```

```js
[assign]
path = doi
value = get("DO")
```

:point_down:

```json
[{
    "DO": "10.3390/info10050178 ",
    "TI": "Istex: A Database of Twenty Million Scientific Papers with a Mining Tool Which Uses Named Entities",
    "SO": "Information",
    "doi": "10.3390/info10050178 "
}]
```

Dans un `[assign]`, on peut crÃ©er autant de nouveaux champs que lâ€™on veut, tant quâ€™ils sâ€™appuient uniquement sur les champs existants du dataset original.  

On peut donc les dÃ©finir dans le mÃªme bloc `[assign]`.

```js
[assign]
path = doi
value = get("DO")

path = normalizedTitle
value = get("TI").deburr().toLower()

path = normalizedSource
value = get("SO").deburr().toLower()
```

âš ï¸ Attention :  

Un champ crÃ©Ã© dans un `[assign]` nâ€™est pas utilisable immÃ©diatement dans ce mÃªme bloc.  
Il ne devient disponible quâ€™Ã  la sortie du bloc, câ€™est-Ã -dire pour les instructions suivantes.  

Si l'on souhaite crÃ©er un champ contenant le doi ou, s'il n'existe pas, le titre normalisÃ©, on ne peut ajouter ceci dans le bloc :

```js
path = doiOrNormalizedTitle
value = get("doi").thru(doi => _.isEmpty(doi) ? self.normalizedTitle : doi)
```

Il faut ouvrir un nouvel `[assign]`

```js
[assign]
path = doiOrNormalizedTitle
value = get("doi").thru(doi => _.isEmpty(doi) ? self.normalizedTitle : doi)
```

RÃ©sultat :

```json
[{
    "DO": "10.3390/info10050178 ",
    "TI": "Istex: A Database of Twenty Million Scientific Papers with a Mining Tool Which Uses Named Entities",
    "SO": "Information",
    "doi": "10.3390/info10050178 ",
    "normalizedTitle": "istex: a database of twenty million scientific papers with a mining tool which uses named entities",
    "normalizedSource": "information",
    "doiOrNormalizedTitle": "10.3390/info10050178 "
}]
```

ðŸ”‘ **Ã€ retenir : `[assign]` permet dâ€™ajouter de nouveaux champs ou de modifier des champs existants (sâ€™ils portent le mÃªme nom), tout en conservant lâ€™objet original.**  
**On enrichit donc ce dernier, au lieu de le remplacer.**

---

### [replace]

On a vu que lâ€™on pouvait modifier des valeurs ou ajouter de nouveaux champs avec `[assign]`, ce qui permet dâ€™enrichir lâ€™objet tout en conservant ses donnÃ©es originales.  

Mais il arrive quâ€™on trouve les noms de champs du dataset peu intelligibles (DO, TI, SO...) ou pas adaptÃ©s Ã  nos besoins. PlutÃ´t que d'empiler des `[assign]` puis de supprimmer les champs originaux ensuite, il faut utiliser `[replace]` qui permet de reconstruire un objet en lieu et place de l'original.  

Ainsi : 

```js
[replace]
path = doi
value = get("DO")

path = normalizedTitle
value = get("TI").deburr().toLower()

path = normalizedSource
value = get("SO").deburr().toLower()
```

retourne :

```json
[{
    "doi": "10.3390/info10050178 ",
    "normalizedTitle": "istex: a database of twenty million scientific papers with a mining tool which uses named entities",
    "normalizedSource": "information"
}]
```

Lâ€™instruction `[replace]` permet de **remplacer complÃ¨tement lâ€™objet courant** par un nouveau que l'on dÃ©finit dans le mÃªme bloc.  

Si lâ€™on veut crÃ©er un champ supplÃ©mentaire Ã  partir de lâ€™objet dÃ©jÃ  modifiÃ©, comme dans l'exemple d'`[assign]` avec *doiOrNormalizedTitle* attention au piÃ¨ge !

Il faudra ici ajouter `[assign]` pour crÃ©er le champ *doiOrNormalizedTitle* et non pas `[replace]`.  

Si l'on ouvre un nouveau bloc `[replace]`, il va remplacer celui que l'on avait crÃ©Ã© juste avant :

```js
[replace]
path = doi
value = get("DO")

path = normalizedTitle
value = get("TI").deburr().toLower()

path = normalizedSource
value = get("SO").deburr().toLower()

[replace]
path = doiOrNormalizedTitle
value = get("doi").thru(doi => _.isEmpty(doi) ? self.normalizedTitle : doi)
```

:point_down:

```json
[{
    "doiOrNormalizedTitle": "10.3390/info10050178 "
}]
```

`[replace]` n'est donc pas cumulatif comme l'est `[assign]`.

ðŸ”‘ **Ã€ retenir : [replace] reconstruit un objet neuf en remplaÃ§ant complÃ¨tement lâ€™objet courant. Tous les champs non explicitement redÃ©finis disparaissent.**

---

### [exchange]
### [remove]
### [dedupe]
### [aggregate]

## ...

### DÃ©finir des fonctions rÃ©utilisables

On a dÃ©jÃ  vu qu'avec l'instruction `[ENV]` il Ã©tait possible de stocker un dictionnaire que l'on pouvait rÃ©utiliser.  

De la mÃªme maniÃ¨re, `[ENV]` peut contenir des **fonctions utilitaires**, que l'on dÃ©finit une fois et que l'on rÃ©utilise ensuite Ã  plusieurs endroits du pipeline.  

Par exemple, on a un jeu de donnÃ©es qui va contenir beaucoup de *boolÃ©ens* (is openacces, has repository, is retracted etc). Dans Lodex on souhaiterait afficher des "Oui" ou "Non" plutÃ´t que les *boolÃ©ens*.  

On va d'abord Ã©cire notre fonction dans `[ENV]` et la nommer correctement (c'est souvent la partie la plus compliquÃ©e).

```js
[env]
path = labelizeBoolean
value = fix((bool)=> bool === true ? "Oui" : bool === false ? "Non" : "Inconnu")
```

On utilise `fix` pour dÃ©clarer notre fonction, puis on Ã©crit une simple *ternaire*.  

Il suffit ensuite dans un `[assign]` de dÃ©clarer le champ que l'on veut transformer, puis d'appeler la *variable d'environnement* dans un `thru`.

```js
[assign]
path = value
value = get("isRetracted").thru(env("labelizeBoolean"))
// EntrÃ©e : true â†’ Sortie : "Oui"
```

Et si notre champ ne contient pas un seul, mais plusieurs *boolÃ©ens* dans un tableau, il suffit de remplacer `thru` par `map` !

```js
[assign]
path = value
value = get("isCnrs").map(env("labelizeBoolean"))
// EntrÃ©e :  [false, true, true, false] â†’ Sortie : ["Non","Oui","Oui","Non"]
```

Une fois cette logique acquise, on peut aller encore plus loin et se lancer dans **la composition de fonctions**.  

PlutÃ´t que dâ€™Ã©crire de longs traitements redondants, on crÃ©e de petites briques spÃ©cialisÃ©es (nettoyer une chaÃ®ne, nettoyer un tableau), puis on les enchaÃ®ne et les combine pour construire des transformations plus complexes.  

---

A titre d'exemple, on souhaite "normaliser" les champs contenant des chaÃ®nes de caractÃ¨res (titre, rÃ©sumÃ©...). On souhaite Ã©galement rÃ©aliser ces opÃ©rations sur les Ã©lÃ©ments de certains tableaux comme les mots clÃ©s. Et enfin on souhaite que donnÃ©es sous formes de tableaux soient dÃ©doublonnÃ©es, triÃ©es et vidÃ©es de leurs valeurs falsy (null, ""...).  

On construit notre premiÃ¨re brique : 

```js
[env]
path = normalizeString
value = fix((str)=> \
  _.toLower( \
    _.deburr( \
      _.trim(str) \
    ) \
  ) \
)
```

> [!NOTE]
> On le sait, utiliser `=>` nous fait passer dans du **JavaScript pur**.  
> Mais pour rÃ©aliser un chaÃ®nage **Lodash** dans une fonction anonyme il convient de mettre le prÃ©fixe `_` avant chaque fonction comme ici.  
> Mais lorsque l'on combine des fonctions, la lecture peut devenir difficile. Dans cet exemple, `trim` est d'abord utilisÃ©e, puis `deburr` et enfin `toLower`.
>
> Il existe une autre faÃ§on de dÃ©clarer un chaÃ®nage, qui est sans doute plus lisible :
>
> Il faut placer la valeur Ã  transformer dans un **wrapper Lodash**. LittÃ©ralement cela signifie que l'on *emballe* la valeur dans un objet spÃ©cial afin de pouvoir la passer dans un pipeline de transformations.  
> Et comme vu [ici](https://github.com/AnaelKremer/Atelier-Lodash-usage-Lodex/blob/main/01-introduction.md#un-encha%C3%AEnement-de-fonctions-lodash) un pipeline **Lodash** doit commencer par `_.chain` et se conclure par `.value()`.

On peut donc Ã©crire notre premiÃ¨re brique comme cela :

```js
[env]
path = normalizeString
value = fix((str)=> \
  _.chain(str) \
    .trim() \
    .deburr() \
    .toLower() \
    .value() \
)
```

Puis la tester sur une chaÃ®ne de caractÃ¨res :

```js
[assign]
path = normalizedTitle
value = get("value.title").thru(env("normalizeString"))
// EntrÃ©e :  "BibliomÃ©trie prÃªte Ã  l'emploi avec OpenAlex : retour d'expÃ©rience" 
// â†’ Sortie : "bibliometrie prete a l'emploi avec openalex : retour d'experience"
```

On peut ensuite crÃ©er notre deuxiÃ¨me brique destinÃ©e Ã  traiter des tableaux (que l'on ajoute dans [ENV] en dessous de la premiÃ¨re) :

```js
path = cleanArray
value = fix((arr) => \
  _.chain(arr) \
    .compact() \
    .uniq() \
    .sort() \
    .value() \
)
```

On peut enfin utiliser nos deux briques sur un mÃªme champ :

```js
path = normalizedAllKeywords
value = get("value.authorsKeywords") \
    .concat(self.value.keywords) \
    .map(env("normalizeString")) \
    .thru(env("cleanArray"))
```

:point_down:

```json
{
  "authorsKeywords": [
    "bibliomÃ©trie",
    "openalex",
    "cnrs-inist",
    "retour dâ€™expÃ©rience"
  ],
  "keywords": [
    "bibliometrie",
    "OpenAlex",
    "CNRS-INIST",
    "expÃ©rience utilisateur",
    "Lodex"
  ],
  "normalizedAllKeywords": [
    "bibliometrie",
    "cnrs-inist",
    "experience utilisateur",
    "lodex",
    "openalex",
    "retour dâ€™experience"
  ]
}
```